{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 15:47:09,650 [DEBUG] load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-11-17 15:47:09,652 [DEBUG] load_verify_locations cafile='/opt/anaconda3/envs/aienv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "2024-11-17 15:47:09,657 [DEBUG] load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-11-17 15:47:09,657 [DEBUG] load_verify_locations cafile='/opt/anaconda3/envs/aienv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "2024-11-17 15:47:09,677 [DEBUG] connect_tcp.started host='api.gradio.app' port=443 local_address=None timeout=3 socket_options=None\n",
      "2024-11-17 15:47:09,681 [DEBUG] load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-11-17 15:47:09,682 [DEBUG] load_verify_locations cafile='/opt/anaconda3/envs/aienv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "2024-11-17 15:47:09,728 [DEBUG] load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-11-17 15:47:09,729 [DEBUG] load_verify_locations cafile='/opt/anaconda3/envs/aienv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "2024-11-17 15:47:09,791 [DEBUG] Importing BlpImagePlugin\n",
      "2024-11-17 15:47:09,792 [DEBUG] Importing BmpImagePlugin\n",
      "2024-11-17 15:47:09,793 [DEBUG] Importing BufrStubImagePlugin\n",
      "2024-11-17 15:47:09,794 [DEBUG] Importing CurImagePlugin\n",
      "2024-11-17 15:47:09,795 [DEBUG] Importing DcxImagePlugin\n",
      "2024-11-17 15:47:09,796 [DEBUG] Importing DdsImagePlugin\n",
      "2024-11-17 15:47:09,798 [DEBUG] Importing EpsImagePlugin\n",
      "2024-11-17 15:47:09,799 [DEBUG] Importing FitsImagePlugin\n",
      "2024-11-17 15:47:09,799 [DEBUG] Importing FliImagePlugin\n",
      "2024-11-17 15:47:09,800 [DEBUG] Importing FpxImagePlugin\n",
      "2024-11-17 15:47:09,801 [DEBUG] Image: failed to import FpxImagePlugin: No module named 'olefile'\n",
      "2024-11-17 15:47:09,801 [DEBUG] Importing FtexImagePlugin\n",
      "2024-11-17 15:47:09,801 [DEBUG] Importing GbrImagePlugin\n",
      "2024-11-17 15:47:09,802 [DEBUG] Importing GifImagePlugin\n",
      "2024-11-17 15:47:09,805 [DEBUG] Importing GribStubImagePlugin\n",
      "2024-11-17 15:47:09,805 [DEBUG] Importing Hdf5StubImagePlugin\n",
      "2024-11-17 15:47:09,806 [DEBUG] Importing IcnsImagePlugin\n",
      "2024-11-17 15:47:09,807 [DEBUG] Importing IcoImagePlugin\n",
      "2024-11-17 15:47:09,808 [DEBUG] Importing ImImagePlugin\n",
      "2024-11-17 15:47:09,808 [DEBUG] Importing ImtImagePlugin\n",
      "2024-11-17 15:47:09,809 [DEBUG] Importing IptcImagePlugin\n",
      "2024-11-17 15:47:09,810 [DEBUG] Importing JpegImagePlugin\n",
      "2024-11-17 15:47:09,811 [DEBUG] Importing Jpeg2KImagePlugin\n",
      "2024-11-17 15:47:09,811 [DEBUG] Importing McIdasImagePlugin\n",
      "2024-11-17 15:47:09,812 [DEBUG] Importing MicImagePlugin\n",
      "2024-11-17 15:47:09,813 [DEBUG] Image: failed to import MicImagePlugin: No module named 'olefile'\n",
      "2024-11-17 15:47:09,813 [DEBUG] Importing MpegImagePlugin\n",
      "2024-11-17 15:47:09,813 [DEBUG] Importing MpoImagePlugin\n",
      "2024-11-17 15:47:09,815 [DEBUG] Importing MspImagePlugin\n",
      "2024-11-17 15:47:09,815 [DEBUG] Importing PalmImagePlugin\n",
      "2024-11-17 15:47:09,817 [DEBUG] Importing PcdImagePlugin\n",
      "2024-11-17 15:47:09,818 [DEBUG] Importing PcxImagePlugin\n",
      "2024-11-17 15:47:09,818 [DEBUG] Importing PdfImagePlugin\n",
      "2024-11-17 15:47:09,821 [DEBUG] Importing PixarImagePlugin\n",
      "2024-11-17 15:47:09,822 [DEBUG] Importing PngImagePlugin\n",
      "2024-11-17 15:47:09,822 [DEBUG] Importing PpmImagePlugin\n",
      "2024-11-17 15:47:09,822 [DEBUG] Importing PsdImagePlugin\n",
      "2024-11-17 15:47:09,826 [DEBUG] Importing QoiImagePlugin\n",
      "2024-11-17 15:47:09,837 [DEBUG] Importing SgiImagePlugin\n",
      "2024-11-17 15:47:09,858 [DEBUG] Importing SpiderImagePlugin\n",
      "2024-11-17 15:47:09,860 [DEBUG] Importing SunImagePlugin\n",
      "2024-11-17 15:47:09,860 [DEBUG] Importing TgaImagePlugin\n",
      "2024-11-17 15:47:09,861 [DEBUG] Importing TiffImagePlugin\n",
      "2024-11-17 15:47:09,861 [DEBUG] Importing WebPImagePlugin\n",
      "2024-11-17 15:47:09,867 [DEBUG] Importing WmfImagePlugin\n",
      "2024-11-17 15:47:09,869 [DEBUG] Importing XbmImagePlugin\n",
      "2024-11-17 15:47:09,873 [DEBUG] Importing XpmImagePlugin\n",
      "2024-11-17 15:47:09,874 [DEBUG] Importing XVThumbImagePlugin\n",
      "2024-11-17 15:47:09,973 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1105a6f20>\n",
      "2024-11-17 15:47:09,973 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x10f876dc0> server_hostname='api.gradio.app' timeout=3\n",
      "2024-11-17 15:47:10,548 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1105a6ef0>\n",
      "2024-11-17 15:47:10,549 [DEBUG] send_request_headers.started request=<Request [b'GET']>\n",
      "2024-11-17 15:47:10,555 [DEBUG] send_request_headers.complete\n",
      "2024-11-17 15:47:10,555 [DEBUG] send_request_body.started request=<Request [b'GET']>\n",
      "2024-11-17 15:47:10,555 [DEBUG] send_request_body.complete\n",
      "2024-11-17 15:47:10,556 [DEBUG] receive_response_headers.started request=<Request [b'GET']>\n",
      "2024-11-17 15:47:10,831 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 17 Nov 2024 10:17:10 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'3'), (b'Connection', b'keep-alive'), (b'Server', b'nginx/1.18.0'), (b'Access-Control-Allow-Origin', b'*')])\n",
      "2024-11-17 15:47:10,833 [INFO] HTTP Request: GET https://api.gradio.app/gradio-messaging/en \"HTTP/1.1 200 OK\"\n",
      "2024-11-17 15:47:10,833 [DEBUG] receive_response_body.started request=<Request [b'GET']>\n",
      "2024-11-17 15:47:10,833 [DEBUG] receive_response_body.complete\n",
      "2024-11-17 15:47:10,834 [DEBUG] response_closed.started\n",
      "2024-11-17 15:47:10,834 [DEBUG] response_closed.complete\n",
      "2024-11-17 15:47:10,835 [DEBUG] close.started\n",
      "2024-11-17 15:47:10,837 [DEBUG] close.complete\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp as youtube_dl\n",
    "import requests\n",
    "import pytube\n",
    "import re\n",
    "import gradio as gr\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.llms import Ollama\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() ## load all the environment variables\n",
    "\n",
    "import streamlit as st\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 15:47:10,924 [DEBUG] load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-11-17 15:47:10,925 [DEBUG] load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-11-17 15:47:10,926 [DEBUG] load_verify_locations cafile='/opt/anaconda3/envs/aienv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "2024-11-17 15:47:10,944 [DEBUG] load_verify_locations cafile='/opt/anaconda3/envs/aienv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "2024-11-17 15:47:10,982 [DEBUG] connect_tcp.started host='api.gradio.app' port=443 local_address=None timeout=3 socket_options=None\n",
      "2024-11-17 15:47:10,982 [DEBUG] connect_tcp.started host='checkip.amazonaws.com' port=443 local_address=None timeout=3 socket_options=None\n",
      "2024-11-17 15:47:11,033 [DEBUG] load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-11-17 15:47:11,033 [DEBUG] load_verify_locations cafile='/opt/anaconda3/envs/aienv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "2024-11-17 15:47:11,050 [DEBUG] connect_tcp.started host='127.0.0.1' port=7860 local_address=None timeout=None socket_options=None\n",
      "2024-11-17 15:47:11,050 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1309eef50>\n",
      "2024-11-17 15:47:11,051 [DEBUG] send_request_headers.started request=<Request [b'GET']>\n",
      "2024-11-17 15:47:11,051 [DEBUG] send_request_headers.complete\n",
      "2024-11-17 15:47:11,052 [DEBUG] send_request_body.started request=<Request [b'GET']>\n",
      "2024-11-17 15:47:11,052 [DEBUG] send_request_body.complete\n",
      "2024-11-17 15:47:11,053 [DEBUG] receive_response_headers.started request=<Request [b'GET']>\n",
      "2024-11-17 15:47:11,053 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Sun, 17 Nov 2024 10:17:11 GMT'), (b'server', b'uvicorn'), (b'content-length', b'4'), (b'content-type', b'application/json')])\n",
      "2024-11-17 15:47:11,054 [INFO] HTTP Request: GET http://127.0.0.1:7860/startup-events \"HTTP/1.1 200 OK\"\n",
      "2024-11-17 15:47:11,054 [DEBUG] receive_response_body.started request=<Request [b'GET']>\n",
      "2024-11-17 15:47:11,054 [DEBUG] receive_response_body.complete\n",
      "2024-11-17 15:47:11,054 [DEBUG] response_closed.started\n",
      "2024-11-17 15:47:11,055 [DEBUG] response_closed.complete\n",
      "2024-11-17 15:47:11,055 [DEBUG] close.started\n",
      "2024-11-17 15:47:11,056 [DEBUG] close.complete\n",
      "2024-11-17 15:47:11,058 [DEBUG] load_ssl_context verify=False cert=None trust_env=True http2=False\n",
      "2024-11-17 15:47:11,058 [DEBUG] connect_tcp.started host='127.0.0.1' port=7860 local_address=None timeout=3 socket_options=None\n",
      "2024-11-17 15:47:11,059 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x130a1c370>\n",
      "2024-11-17 15:47:11,059 [DEBUG] send_request_headers.started request=<Request [b'HEAD']>\n",
      "2024-11-17 15:47:11,060 [DEBUG] send_request_headers.complete\n",
      "2024-11-17 15:47:11,060 [DEBUG] send_request_body.started request=<Request [b'HEAD']>\n",
      "2024-11-17 15:47:11,061 [DEBUG] send_request_body.complete\n",
      "2024-11-17 15:47:11,062 [DEBUG] receive_response_headers.started request=<Request [b'HEAD']>\n",
      "2024-11-17 15:47:11,069 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Sun, 17 Nov 2024 10:17:11 GMT'), (b'server', b'uvicorn'), (b'content-length', b'10135'), (b'content-type', b'text/html; charset=utf-8')])\n",
      "2024-11-17 15:47:11,069 [INFO] HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
      "2024-11-17 15:47:11,069 [DEBUG] receive_response_body.started request=<Request [b'HEAD']>\n",
      "2024-11-17 15:47:11,070 [DEBUG] receive_response_body.complete\n",
      "2024-11-17 15:47:11,070 [DEBUG] response_closed.started\n",
      "2024-11-17 15:47:11,070 [DEBUG] response_closed.complete\n",
      "2024-11-17 15:47:11,071 [DEBUG] close.started\n",
      "2024-11-17 15:47:11,071 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1308c0fd0>\n",
      "2024-11-17 15:47:11,072 [DEBUG] close.complete\n",
      "2024-11-17 15:47:11,072 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x1307a4140> server_hostname='checkip.amazonaws.com' timeout=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 15:47:11,075 [DEBUG] load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-11-17 15:47:11,076 [DEBUG] load_verify_locations cafile='/opt/anaconda3/envs/aienv/lib/python3.10/site-packages/certifi/cacert.pem'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from dotenv import load_dotenv\n",
    "import ollama\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set up constants for the Ollama API\n",
    "OLLAMA_MODEL = \"llama3.2-vision\"  # Ensure this is the correct model name\n",
    "BASE_URL = \"http://localhost:11434\"\n",
    "TEMPERATURE = 0.7\n",
    "\n",
    "# Nutrition analysis prompt\n",
    "INPUT_PROMPT = \"\"\"\n",
    "You are an expert nutritionist. Analyze the food items in the provided image and calculate the total calories.\n",
    "Provide details of each food item with its calorie intake in the following format:\n",
    "\n",
    "1. Item 1 - [calories]\n",
    "2. Item 2 - [calories]\n",
    "----\n",
    "\"\"\"\n",
    "\n",
    "def process_uploaded_image(uploaded_image):\n",
    "    \"\"\"Convert the uploaded image to bytes and save it as a temporary file.\"\"\"\n",
    "    if uploaded_image is None:\n",
    "        raise ValueError(\"No image uploaded\")\n",
    "\n",
    "    # Convert the PIL Image to bytes and save as a temporary file\n",
    "    buffered = BytesIO()\n",
    "    uploaded_image.save(buffered, format=\"JPEG\")\n",
    "    image_bytes = buffered.getvalue()\n",
    "    \n",
    "    # Save the image bytes to a temporary file\n",
    "    image_path = \"temp_image.jpg\"\n",
    "    with open(image_path, \"wb\") as f:\n",
    "        f.write(image_bytes)\n",
    "    \n",
    "    return image_path\n",
    "\n",
    "def get_ollama_response(user_input, image_path):\n",
    "    \"\"\"Generate a response using the Ollama LLM with image support.\"\"\"\n",
    "    try:\n",
    "        # Use ollama.chat() method with image support\n",
    "        response = ollama.chat(\n",
    "            model=OLLAMA_MODEL,\n",
    "            messages=[{\n",
    "                'role': 'user',\n",
    "                'content': f\"{INPUT_PROMPT}\\n{user_input}\",\n",
    "                'images': [image_path]\n",
    "            }]\n",
    "        )\n",
    "        \n",
    "        # Extract the text from the response\n",
    "        if response and 'response' in response:\n",
    "            result_text = response['response']\n",
    "        else:\n",
    "            result_text = 'No response received from the model.'\n",
    "        \n",
    "        print(f\"Ollama Response: {result_text}\")  # For debugging\n",
    "        return result_text\n",
    "    except Exception as e:\n",
    "        return f\"Error generating response: {e}\"\n",
    "\n",
    "def gemini_health_app(image, user_input):\n",
    "    \"\"\"Main function to process input and generate a response.\"\"\"\n",
    "    try:\n",
    "        # Convert the uploaded image to a temporary file path\n",
    "        image_path = process_uploaded_image(image)\n",
    "        \n",
    "        # Get the Ollama response with image and user input\n",
    "        response = get_ollama_response(user_input, image_path)\n",
    "        \n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"Error processing request: {e}\"\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=gemini_health_app,\n",
    "    inputs=[\n",
    "        gr.Image(type=\"pil\", label=\"Upload Food Image\"),\n",
    "        gr.Textbox(label=\"Additional Input (Optional)\", placeholder=\"E.g., Any dietary restrictions?\")\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Calorie Analysis Result\"),\n",
    "    title=\"Gemini Health App\",\n",
    "    description=\"Upload an image of food items to get a detailed calorie count and nutrition analysis.\",\n",
    "    allow_flagging=\"never\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio interface\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 15:52:21,440 [INFO] Launching Gemini Health App...\n",
      "2024-11-17 15:52:21,444 [INFO] Starting Gemini Health App analysis...\n",
      "2024-11-17 15:52:21,444 [INFO] Opening image from path: /Users/vinitpahwa/Documents/GENAIProjects/YouTuberSummarizer/myfood.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 15:52:21,456 [DEBUG] Original image size: (900, 1600)\n",
      "2024-11-17 15:52:21,491 [INFO] Image optimized and saved at: optimized_image.jpg\n",
      "2024-11-17 15:52:21,493 [DEBUG] Optimized image size: (225, 400)\n",
      "2024-11-17 15:52:21,494 [DEBUG] Prepared messages for Ollama: [{'role': 'user', 'content': 'What is in this image?', 'images': ['/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDABsSFBcUERsXFhceHBsgKEIrKCUlKFE6PTBCYFVlZF9VXVtqeJmBanGQc1tdhbWGkJ6jq62rZ4C8ybqmx5moq6T/2wBDARweHigjKE4rK06kbl1upKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKT/wAARCAGQAOEDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwCwBx1HX16UpOAcc9c/rTQpI9vr1p3YnJOP060ALjk49aUHkZ25OOMUh5PT8D/nij+Lnp/KgBxIZT6+tNLA+2PX8aBkDn8KMD65PODmgAVgO3X0NOx14OT3pm0KAM5IqVCcnOOBQAALuOR1P5UnGRwOcdeamBjKkkVGWAOQAPTNAh8KkNlgCKtxSkKF2jiqaS7SOPxFTpKoHDD1xTAmkkcgjp2qpMTuwDjHvUklwCBVbduJ3dT+lIBFyQcg8YpRngnrQn3W/UjmlBGcngeg9aBiHkdKXJxu49sUo2gHOCDQTx1/z+dAAPvdOPrSk8+9N57HnBoyfTPPpQA1uSe+OtRvlSuR1yPcVIcZzgY9cUxseYBnnnikAN9+L3iFSN0FMk+/AfWGpX+7SWwyKpI+veo+pqWPqO9CBlmRtqZFUm5NTzSZGB0qAHnJ7U2JDdp9KKXcaKRRFjGc9OtOGT268gCjjbyPxpSTyME/h9etMkCwAIA+h9qUfUjHrTicsfccnFGVUBTk54IzQAi89s89Pypec8Yyf7pxTAwJ7Lnpz9KTzATyQB/KgCTjbgjB+tG49AQRjAppYKeSOPQ08NuUsuDgZwFpgJ6/yIpCCSGHH40gk9fT0PvT03NkqrHvypoEKvXjg56UuFC/54pfn3cRsc8cg00hl6Ix/wCA0AKxIwB36UADA9/fio9jMMbW/lThFIGIwB9SOaABQcnp078EUDjqf1puGRsEfhuzjpT2OBwMUDFUnjPP1PNLgAc9OKRST1zijd8v49e1ACsB7mm9B0owVX69BTSxz6e+P1pAKR0GB6cVHJyy4I6ntThu9BTX3FhzQA5/vW3/AFxqWU8DNRScG2/641LIOBSWwyIdalXgVGo5qUdKEA1zmo/ant70zvQAY96KM0UgGC3fGCPzkH+NPMJZQB5SH18z/wCvVYWOf+W7f99ClFhGesx/F6rURZW3Qfee349WzUq4QYW4t1HoB/8AWqp/Z1tjJn/8eNH9n2uOJgT7k0agW/3f8VxB/wB80oeJRgXcY+i1UXT7XHLofzp4sLLHLA454U0a9xE5lg73o/KmtNa4wbz/AMdpi2WnDqjNz6Yp7WmnAkeUwI44FGvcYwzWXe7P4LSfaLAHm6c/gKeLaxHSJzj2FSLHZo3EBP4Ciz7gQfarADiSZvpQL2zz8qTsfxq0ZbdAw+YLVC5v8HbF8q+vek9Oo0m9ic3sCED7JLn3zQL23zlrZR9WrM8xnPzEk/zo5IBHapuaqkaEciOSQ6gk9AelP2Y61mFBgNznNSxSvE3yt7+1PmB0uxpCLglzj0Xv/wDrpCenY+9RR3Sy/f4f9DTiSTnj2PaquZNNbin+7tyemKaFOc4/T9aUJ7U8AA5oEIAAPb0qOQH3xmpSMDtxUUhJ5wcCmAsn37X/AK5VJJ0Apkg+a1/65U5+1SthiKKdzQBhaX1pgRvTRSt1oUVIBiinZNFMCBBxyAQBR3Ax29O1KCOe1KORjGaYg7cjGOtBHP4+uaOMZxzTu/oBzjpQAKNpOfp70oXONu7qcUBckHqMfl/9alC846DvmgAwS2QMZ9KUYIH+R/n2o6sScj60YGAwPemAAexHGfrTZGSIEtwe3vT5JNil26Csu4laZiScUmyoxuOmnaUj0z0FR8EkAZBpFxu6gA1Imcg9KzZ0pJBGhx15okXABFSBRjdT8bhnigdyIjCgMp5NNcBXHYVO4AGB0xTW4XnBHSkBGMZI69xVi2nw21un8qr9vQEdaRec88ihOxMo3RqhQSeKUZ9O9V7OXeChzkdKnI781qnc5mrOwHA69aik5zgnt1qQnJ6Uxz1470CCTraH/pl/UU48kU2U8Wn/AFzP8xUiDjdUrYYN1AFI5wKcvJzTHOTmmAynAcUgFOxQAmKKXB9aKAIFHvwKXnr09eaaOPx9KcBx14piFwCevtSdv50oIxx27UAc8beO4oAVQNw4I45/z604dmHGOOlGMYJGfX/P9aMZ5/z0oAUoAcdcU5SPlPBH8qbt5zjr+dOQeg6ng0wKd/IThO4GT71Rznmpbl98rsBjJ4qADg5qGbw0RIACOOCOamBBTI5qJRkDvUiL8vpUmhKnK4p64UfTrUS5PIPSnljimID19abICw5wDT9pK+5pkmQvTmkMYVAWmqoH04pcnuKCOnX1PtUsY6JzE28dq0d6SHCTRsfTdgj8KzE5U+5rPvxtuSRxkA1cH0Mai6nSGNl4KmmN061zsN7cwf6uZgPTORV+HWSRtnjBHqvFWZWNGb7lp/ut/MVOB8gHrVRZorlYRE4Ijzn159qvL90H2pJCI3+UYFRmnOcmkAoGCilApQKUUAGKKfgUUxFP5iBn04z0peQM9KGJx1IHagAcdzQAozkc8npzil7dMD1x3pMYzkcA9D3pVPTjigBcAAEHjoc8/wCfpQMNgdPekwSSM5GeMd6UkKCzf4UwHDjg8VDNdRQkJv8AnPAArPvdUIzHB+JrNhdmukZiSc96QJGg3XNMHB9qVuvtSHg9Kk6EPUkD27VJG3GO/eoc06PrwOaRSLCNnk/pUoXBBPSo4z8uO5p27161LYybPfP0pAFI555qANz17UpcnA6CkpANdNxOKbn5iM9BT3bYrHrxUWecgknvmle4x33UwO1UL0ZdT7VfJ9RVeaPec+lVHcznsZ+KM+tWWhqNo61MhiSFGBUkEdxWrZaqRhJj+NZRTFNzikB1SsHGVNOAxWFYXxiYI5+XsfSt1JBIuRQIUU5fpSAU8dKYhOPSijmigRTxtGacAedmckdu9IOuevvShhyxGc+tAAeeOcCgY7j6YpcckHj1zSD3zwc0ALuCoSTgCsm+u2lJVThe59alvrgt+7U4Hf2rPkOKLgQtSJlXDehzTwuTT1iJ7UDLSnI9jS5/Oo1VlABp2c8ioNk7oDxmnRMBg00mlC9KTY0ThueelEr4XINQNIR0qJ5Djk8VL1C5OkmSeeakaTjg81lPK6uCverkDNIOeD6UONhKRM02TinK2enFMERz0qQIQtSWKT2zVrT4llMu4ZwBVJhjk1LZ3r2xOEyrnrWkNyZ7FqeyXBOcAVTNsCevFS3F09w2SMKOiimx5bpVOXYIUrasb9khH3gT+NDWtsRjygPfJqbZ6nNIQoPFTdmnKim9hH/A5B9+ansZpIHEUvT+E9j7U9mA7ZpOGHShSJlTXQ148MoYdDTm4FUbW7EXyS5CnofSrrEEZByDV3Odprcbmim5ooEV8HGe/pQP88UNnnnpTlxzkHp9KYhDzgCmS7yuyNcnHNS4zwc49OlSKM8AcVnOolohpGfHpZY5mlAJ5IUZqYaTbfxbyfUtV4L6GgDBxWPPIoz20qD+EsPxzTBp+w8NuH0rTIOMdBTSueuaFUkhWKklsksJj6MOQfessqQSp4IOCK2mXg5GKyr+0eNjNHk+oNaKpzblR0ICKlU/LVZJFce/cVMpwOMYoZaGOBniopEJHpVsIGGaRk3EKBSTBq5QETB1OMnNX7WExjLck1Yht8445NTGIIxXORRKV9BKNgQIv3m61FcSoq7V/OobncvAOaqOzdzzSSuWSTTARMwOewoiZ5FXe2dowB2AqpMG83yzxt5Iq5ApwK0tZFR1dyyBgAGnJwaTJwM/rSZwak1LLOCoAH1NPjC7emSfSqrP6VNFcBeCKpGchxhVjk5z7UwRkDIHFT+YrDrz1xTQ4wSe1DQRZEQpU5pbSfyj5bH92T/3yahlcBjUO7HI6UkxygmbWKKxfONFVcx9kaRAAyDTuDn0pG+9364J70uOTg+1U3YwHJ7mpVFRqMcU9c9q42WPz6il680zPNLuOAeooEPzkcdqRsDrmm7h0NNZge5NMBCeTz+FRyrlCDgipDg9RTDjAzxSGYF/bGOQunFRQ3OcBuK2buIOnIrEuISjnit4vmVmO9i6GyuQadG2HzWWkrx9Dx6Gp1vP7yflQ4MpSRqvdKiZHJqq1zIXJ3HniqjXKt2NNM2egoUWPmRZeXjk0222tOCelViWY805GK5x6VpGNiXK+wgYyTu5/iYmtCEZANUolxV2HoKl6s2hoiZsUlHHagelBTYdOaaQetPAzUcj7TwaCQG8nrxQWwMZqPzsA0nmZNJlIVmJ6mmluOOnWhmGMdz2FNbgHFFh3EyPeimZNFFgub3Qk+3OaAcnOMUccE9TTAcOfr2oqbHEicHFOzmogwJzmlzzgVzjJCcnrS4xgUzdxQG55IxQA79KQccL+dNzx04NKT2Pc0AJ0HqO2aQfdyfwoz7/AJU0nj09qAB1DLjPNZ13BxyDmtID24xxTZI94wTz9KpOwHOSRYNM2Vp3NsVJ4qoU2nnpXRGVwK+ynqlWRAfSpI4CT0qxECRZNI8ZViD2rTht9p5Gar3kWGPvQFysg4qeNiOKrpx8p/Cn7sVm1qdEHdFxQCtAODxiq6zFeOKAxPOaCyRn7elV3JY5qXtio2HHFMRGelICc+9PIpo/KkAoJoZsCm7sCkHznFAN2DdRUuxfSinYz52buOOOnU59ahcYY96lB5JGKjnUkbxjiiaujEbuwakWQVCrZ7c0p+UZH1rmsMnLdKTd3/OoN+aduwM560gJeo5/KjOeOuKi3gLilDYPqcUgJOoOBx2pPfOR3qMOQc08Njluc9KYEmRwB1FOBGME4xUZOenGacCG4HSmAOgYYbnrWZd2uw7l5WtXOO1RPhif5GmnYZnWEi7xDJ3+6f6VpLGq9AKyrqHy33J0/lWlZz+fAG/iHDfWumDuSyTAycCqt2mRk1cx36Vl6nI5YKi5QdcHqasSKUhAbjml6iosENzyaUNjrUNGkXYeODUqtgYFQ7qUHHSoOhO5PkYpGYAdKiLHsaaW96Yx7HNN981Hk55pSSaCWxHNPQbUz0zTRtHJqGWQyey+lUkYykTefF/fP5UVUxRVWIuzrgOeM4P50pHYr+Xemg8dMf570oY88kjvk0iSpKnltwcg9MU3f60apu+y7wSGRgR6iqVteLKNr4V/0NZyiMvlhjmmM2M81HuxSFiRWdhjw9KHyOoFQ5oBx2pcoFjzPfgU5XOfXvVcNzT0I+vNFgLQO786lDDP9aqqcAYxTg57n6UgJmbA+8CD09qjZsD1NMLjtyaA/rQgGzKGUg96ZpuY5JUPsaZNKAcZ4FGnsWkkc9DgVvDcT2NLrkdqp3UI2HaOatbwASxAAHWqN1eb8rHwv949TWrdgjFy2M90CtgqWP6VG0EjnJx+dW1Ap4xWLmdKorqUhbynuoqUW8mOGXNWupAp+zjpScmy1TSM9hInVMj1XmovNB9q1CAeCahktkk+8n400+43F9CjuHrUscMjpvC4X1NW7aKCJ/mQHPQnnFX5E3IQO4q0kznnKS3MCVSKjAq5cQkMRUCp8+KoyIttFXPKopiN4AjAxz2pM87j+FHHfPTvSuCOPyqQK92ge0kUAcqTx+dc0Rg11PHIP0Oa5u4jMc7oexxTAlhupEADfMPfqKsLOjex96orViFckVDimMt59jSZz0NW4kBUDHas68gMM5I6HkUnAakTqcdaf3zU0cKlF4zkVHLHGpxvIPoOaiVNrW41K4gJzQSQfWo8T/wISPcYpG+1Y/1P61l8zTlfYfuNNaXAqu7zg/PGQKb87+1aRi2S7Ieqm5l2qwBFXLdDENpGCOtVEi2EMvBFXjch4Ssi/OB8rCtdYme5FcymU7B90dfc1EEJ4xT0TkA1Kq+1Q5XZ1RhYjEOBkmlCYqfcOB2FOjiaTkDNKxroiBc08D0Jq39nUfKeD9KaYNoGPzp8rEpogIIHIBx1poID7f51OxXZ29KgIAB471LVilINvOCKfAxjby2+6entSblK7T+Bpu4HI7inGVmY1FfQiuXAlyO1US373NS3LHcc1Uz1NdByFnzaKr5NFIDphjhSTn29aXGM4OB39qQkAbcjHrjmgt/CCSBSAYwx3FY2rRbbgP2cZ/Gto4+bd17GqWpxebabwOYz6djTAxV61ctsbhVMcGrELYIpDNiLAUYpl7F50OQPmHSi3bcnvTydxx2FKpNQjccIOTsRQrJ5SqxxgY4qVEVegxSgU9VycV50pym9TujCMFoJigirSwA9hSNCQcbcjsRVexkL2iKjKKge3XqowatOhU45pjCpjKUGVKKmikcAEnjFIPmOR0FPuPlBbjHehAAoxxXc6nNG6OaEOWWoqD8Kf1PGaaOaVDzzUpG1yQqPT681NE5HA6imDkdaBgdDVbCepaEo44Iodvl6/pUJcVGznn+VO5FhxK5weo/SoCPm44+lIZNp9KTcCcnpUNl3sP2BuM4qLIBI9KmyCOwqrKfmBoW5nMr3gw49xVU9cVauzuINQQxmWZUHc4raOxhLcMH0orZ8i1/vUVVibloMoPUdOaMrnGQO9L5tqOssf5GgT2neRPyNTdAMYqQeRTflKlCRtbINTfabEdWH5Gg3unD3/Ci6A5u4hMMzIexpqHFauoJDdhpbfnb1GKygOaYy7bStuCg9a0FGBWdp67p+ewzWivWuPEN3SOugtLj8U4cUgobOOOtc0VqbNkyykDGT7c08Ow5yarjg07cP/wBdaxm+pDihZSzfMc/U8VA1SPzznNRE1E3dlx0ILgfu2+lMQYUVLN/q2+lRxn5B6VtS2JluPFNPByKcOlGK2JsPQ/LzzjvTgQx9eaRBkUmdpOcYpibsPI4P+NMeX5cHikLnGDnFRuuef1zTFvqRsctTgpNPWMZpwAHtUj3GMCEwDUMoJKrnvViRx0GMVVL4ZienSiK1Mp6EE/Q4IOD1FWdNhI3S4/2V+vc0Qw/bJAi4APLH09TV6JVBCx/cThT6+9brYwe5J5Kf3aKloqRjfskC4yq0ot7f+6vNHzKSPzpWPA5/+tTJDybbnEa/lR5EAOPLXPpigBuvHpmkOOwwO/vTuA11jQZVVGfQdayL628p96cxtyPathhjquR3GarNtYMrr8jHnnJHvQBS08/vGH+yavL94VTWFrS7Q9UPQ9iDVk8NXLXWtzrovSxayNlMz60sbgpjIFN9PeuaSNkLmjcMYpM00nNSihxamMaTdUbNxTSAbK3ymoLeYNGAeo4pJ5MKagjjZUDjvXVShoc852ZfzjGDUmc9aopKcYNSrPxya0sCkWxlV45pjtnr0qPzgykfy4pAwVcKSfrQF7koxwetDEL7GojNxjjNN3ls8igLlkMMdc1G8nPy4H4VCWI4BzSBiAeOSOD6UJA2PLZGTUJYZbIB+tI0gAwOfc00ZJqrGbdyxa7gDg43DB+lX4VqCCLAFXY1wKoyYuKKkxRQBGMEDHBHoKFHUEdvpTscHjnqO/8A+umv1AyT/n9aZIYJPAyf5UgHQfl2pRknGf8A9dITkDj6UDGscZBJGB/n6VFIo2Z4B9P89KsbeR8ygdcio5UOM8888UCKrkFSj8rnp3HuP8KYeByc+471NtG4A4Ax1/w/xqLyx1BxxmplHmVi4S5WIrmpPMyKruGU9Kb5tccoNHYpplosKQtVYzUxpqlQY+ZFhpAPrULyZqBpSajZwB8x/Cto0zOUxJ5M1Jby7Yzk/L6VXwHOSwp4jG374rqjGxyylclaVM5Bpw5GQeKqlQPU0LIU+7TauEZWLY4NP3Y69Kqicfxgr71IGyPlO4exrNxNVJDiQD1P50eYMVEcmiiwXJd/c8UhYkdeKYOaWnYVx6rzU9tEXfcRwKLaEyYJ6fzrSjjCjAHFMlsWJKsKKaq4p4oJF59KKKKAIlweMke5oIyAwGB0x0oXAbIXHH0pyDHBb6Z6UyRrDnnA7YpuDt75704+wxSqpPI5J44oGNI+X7v5+tIRwCDml7cHoenalU4xwOB/EOn/ANagCBkO4ZXjPOe9ROqjGMn6+tWcHYCPxzTSgb7vBxk54/z9KBFQjJ5HU4x/nvUTwhjwDVtkO3PGD/8AW/zioiM8EDHT+X+cUmk9xptbFQ27EDbg56e9RGNx1U/gKvlOnYH1/wA/pSFSDgnH1pciK52ZjI56EL+BpEtMnLSr+Oa0WjOAfU9KFUetWtCW7kUFlbf8tLhB+DVO1tp6jAuR+CE0BBge59KYY+mBRcViN4LYEbWkbPT93/8AXqMwAKGUNgjPUCp9hBznpzkUFcdOhouFit9nDH7oz7805Ygp6f0qxtOCR2IHWk28/epDIzEG9QaPsvGd/H0qaPAI3glc8gHmnDBOelA7spiLk89DipoYULsCM4OBmkYHew55bvU0H+tf60guy5EoFTKKYgqVRQA4CnCkFO4oASilz9aKAIgR70gOOCTUIl5yFfpjp1pRKeP3bYAx0qiSXrgAde9IeD/nrTDIccRN0pC7tz5Z/OkMkXIU98+lGMY4/L/PWmEyk8JjHTmjEp6Lz9aLCJCvPToPpTNuQdwzj/P+TSMsp5KAn60hExz8o5560AI+ASMZ9v8AP86jxjHFPZJSTgAD0ppjmz90UANKgKMg57UmBjGc9silaOY44zTfLmBztoACeMDgY5pOGB7E9SfSjypf7poEMuAAnT2oAUKvOSecc46f59KaFBYjg5/vGniGf+6fyprWk5OdpoARlDDPT/PWmbfUDnj6GpRaz4xilFrPjGD0xTAg2gEgZI7UpVhgEe3XipxbXC9A1AtrgY/dk49QaQyAFlPB+8KcoB74zUphuc52P1z9003yLgY/dtx/smgCsy4mA56jrT4B++P1FPeCUHcY3zx/AfWiJSk5Dgr0PIxSYF0CpFFMUjPWn7h60DHilpocetG8DuKAHcUU3zF9f1ooAp/b4h920J/4GaT7ef4bJfxY1z32mb/nq1L9suR0mf8AOnYVjoPt1wfu2kY/Amj7ZedoYx9I6537Zc/895P++qDdXBHM0n/fVOyCzOi+06geiqP+ACj7TqAHOB/wEVzhuJz1lf8A76ppllPWR/zosgszpDeX+M7hj1wKab6/6b1/Kuc8yT++350ebIP4jRZAdF9s1AnAkFNN1f8A/PQ1grOw6k04XH1osgNo3l53mP51G11cN1lJ/GsoTCjzwKVkBqfaJ/8AnqfzNKJ7g9Jv/HqzFmBODUm73osgLwnuCceeP++qDPcAA+cP++qoEAnNKCBRoBe+03C/8tj+dH2q5/57t+dURIvTNP3UWQFo3lx/z8t+dJ9suP8An6b86psMnIoVT3oAufark9Lp/wA6Bc3P/P1J+dV1OBilzRYCz9rnHW5eke4LKS8jMQOM1XC5OTTZDl1UfWiwE4lkx980omlH8RpuKKYDvOl/vGjzpf7xptFAC+bJ/eNFJiigDNxRszT8e1FIqxHsNGKlooHYixSYqbAJ5pNgoAixk0EVIY8U0rjvQIjNJin4NGKYWGYoxT8UlAWG0uT607AxRjigLCbm9aMk96DxRQAuT608TkDBFMHTFLjNILEyzrS+cD0qvtFLigLFhSzHg1OF45PNUhkdDUqzsBzzQDRZKgVGnzXB9hTDMSOKYrMs4x/FQhNF6ijtRTEFFLRQAlFLRQBQxSgLsPUtn8KkUKegokbZ0H41FzYi2NRildiVHqaZn3p6k3QuKVTg5xkUqnOQaQUDDPPtSEA0tFAco3bQVGMU7FAUkEgHA6n0pisM2ikKVJRQFiLyz1o2mpe1OUZzjHHrQKxWIPpRip9oPQ1GVoAZiingUEHPSgBo96cppCDQBQA7ijIpBS4oAXOBToHAlXd9KZjim7SenUUCZp0tRwPvjBPXvUlMkKKKKACiiigCqEzGZAwBB6dzSqwYYNNxijb6YFRub7EbqSxNN2n0qYgjqMD3o5yB607smyGgbRk9aQDGOPxpcE8+9L646UDtcbQBk4pcUoJU5HBFBVgZeTt6e9KFYAjdgHrSc8t3704EOMHg0mxWG4UAkc0zcKVoyinnNR84xTSIbaZIMHpSCkXORTiPmIoGJS0Gigdg/CkpcGlATDbic44xQJobSYGacAx6CkwaADAzxSkDr1pKXI29Oc9aBWGMQKQGnNyMGmbPSmKzJY5ShBH4irsbh1yKz8YHNSW8hjfnoetAmi9RS0UyRKKWigBhtemW59u1N+zH1q43Hy4AA9KTFZXudyikrsqfZ29aT7O/OOfWtBEUxMxY7hjCgdaQI5GAuPrQ3bcVo9Cm1jKsCzHGxjgc81F5Dc4Fan2fj52yBz7UkpSKMlVBz0NLnu7Ilx01MvyX9B7ikMTgHK9Ku+eMcnn0pybJBxjPt3p8zW6DlT2ZQMTA9D60su+VtwQAgYwKu45OBljxQVUEgc07goXKLAsMMKYYs9q0dqnsB7gUnljjHQdc96LicGtzPCBeeppuOpP41faIbT05PHtSNGuTgdaL2FyNlIikxVswZ6CmmAYzTuNxITjYuW3e3pTkVccAU/ycHpUkNq0pcx4G0ZIJ60txONiqXIbGMVHzuIzjFXljR+oGfeoHhbexxmnFoiUWiAH15FKRgj07VIqYPTJ9MVOYvkTI5zQ3YIptFTBpMfnVwwrg/Lg+9NMK+lFy1G6KuKMcVcW2RkY7sMOi460LbyAkKMAjBzRe25PL2HwndEpp+KbBC0QKk5Gal21SdzGSsyPFFSYopiHZiP3JkP14pwjc8qN305rHd+enA9aYjOoLA4J6YNJwN1iH1RvF8oqBNjLnJ7mnRSBmw3DevrWQl9PEAPNLn0bkU7+03P34Y29xwaiVO41VXRGndI7gFMkd1H86rTDZCqEFSzZweooTV4CMNE6/Q5pDPaTv/wAfGwejr/WlBNaMJtSV0yMtgYX5f609CxdWxgn0704QZGUeKQdiripYoGT5nBAFVKyQQu3ca/8ArmHP3R0ox8o4IHv1pRlmLZwzdM0jHOPXvU7I2jrIKKKmh3iKVgoKEYZiOlFi5St0IdvGSfpUkphKRiFWDgfPz1pViU4ySwNPdo4VBPHoB3qOfsS7vcg8hiuW6DuabsGScjJp8kweFiAV2jkVAGcpnIUep71SUmtTO8U7D9hUr2A/lSbflyMjnFOjkIIV8EHoRSn5X+Yn5eQKabvZlbaoj2gngEH60EYHzjFPI4B9eaUHHYfiKPUrl6xGYVT93OKDlm9wMgU/jB45PU0ZAIwOgwKWiFyyYwjAx+I9qbipWQpw4KkdiKMLkcfj2p6juo6DI3KBgACGGDkU5XK843D+VAAxnB54+lJjAOD06ik0LR7D2QSsHRuR2NLiiRlcIEj2OowxB+9TlyVBIwaqOmhz1V1G4op+KK0MD//Z']}]\n",
      "2024-11-17 15:52:21,496 [INFO] Attempt 1: Sending request to Ollama...\n",
      "2024-11-17 15:52:21,497 [INFO] CPU Usage: 19.3% | Available Memory: 319.12 MB\n",
      "2024-11-17 15:52:21,497 [ERROR] Failed to run analysis: name 'ollama' is not defined\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "import logging\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import asyncio\n",
    "import base64\n",
    "import os\n",
    "import time\n",
    "import psutil  # For system resource monitoring (make sure to install this library)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "# Constants\n",
    "MODEL_NAME = 'llama3.2-vision'\n",
    "IMAGE_PATH = '/Users/vinitpahwa/Documents/GENAIProjects/YouTuberSummarizer/myfood.jpeg'\n",
    "TIMEOUT = 90  # Further increased Timeout in seconds\n",
    "MAX_SIZE = (400, 400)  # Reduce image size even more\n",
    "JPEG_QUALITY = 30  # Further reduce quality for optimization\n",
    "MAX_RETRIES = 3  # Number of retries\n",
    "\n",
    "# Step 1: Optimize the Image\n",
    "def optimize_image(image_path, max_size=MAX_SIZE):\n",
    "    try:\n",
    "        logging.info(\"Opening image from path: %s\", image_path)\n",
    "        img = Image.open(image_path)\n",
    "        original_size = img.size\n",
    "        logging.debug(\"Original image size: %s\", original_size)\n",
    "\n",
    "        # Resize the image\n",
    "        img.thumbnail(max_size)\n",
    "        optimized_path = \"optimized_image.jpg\"\n",
    "        img.save(optimized_path, \"JPEG\", quality=JPEG_QUALITY)\n",
    "        optimized_size = img.size\n",
    "        logging.info(\"Image optimized and saved at: %s\", optimized_path)\n",
    "        logging.debug(\"Optimized image size: %s\", optimized_size)\n",
    "        return optimized_path\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error optimizing image: %s\", e)\n",
    "        raise\n",
    "\n",
    "# Monitor system resources\n",
    "def log_system_resources():\n",
    "    cpu_percent = psutil.cpu_percent()\n",
    "    memory_info = psutil.virtual_memory()\n",
    "    logging.info(f\"CPU Usage: {cpu_percent}% | Available Memory: {memory_info.available / (1024 * 1024):.2f} MB\")\n",
    "\n",
    "# Step 2: Asynchronous Call to Ollama with retries\n",
    "async def get_ollama_response_async(model, messages, timeout=TIMEOUT, retries=MAX_RETRIES):\n",
    "    attempt = 1\n",
    "    while attempt <= retries:\n",
    "        try:\n",
    "            logging.info(f\"Attempt {attempt}: Sending request to Ollama...\")\n",
    "            log_system_resources()\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Sending the async request\n",
    "            response = await ollama.chat(\n",
    "                model=model,\n",
    "                messages=messages\n",
    "            )\n",
    "            \n",
    "            end_time = time.time()\n",
    "            logging.info(\"Ollama response received in %.2f seconds\", end_time - start_time)\n",
    "            \n",
    "            if response:\n",
    "                return response\n",
    "            else:\n",
    "                logging.warning(\"Received empty response from Ollama\")\n",
    "        \n",
    "        except ollama.TimeoutError:\n",
    "            logging.warning(f\"Attempt {attempt}: Ollama response timed out after {timeout} seconds\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during Ollama call: {e}\")\n",
    "        \n",
    "        attempt += 1\n",
    "        logging.info(\"Retrying...\")\n",
    "    \n",
    "    return \"Failed to get a response after multiple attempts.\"\n",
    "\n",
    "# Main function to run the entire process\n",
    "async def run_ollama_analysis(image_path):\n",
    "    try:\n",
    "        logging.info(\"Starting Gemini Health App analysis...\")\n",
    "\n",
    "        # Optimize the Image\n",
    "        optimized_image_path = optimize_image(image_path)\n",
    "\n",
    "        # Prepare messages for Ollama\n",
    "        with open(optimized_image_path, \"rb\") as img_file:\n",
    "            encoded_string = base64.b64encode(img_file.read()).decode('utf-8')\n",
    "\n",
    "        messages = [{\n",
    "            'role': 'user',\n",
    "            'content': 'What is in this image?',\n",
    "            'images': [encoded_string]\n",
    "        }]\n",
    "        logging.debug(\"Prepared messages for Ollama: %s\", messages)\n",
    "\n",
    "        # Get response from Ollama asynchronously\n",
    "        response = await get_ollama_response_async(model=MODEL_NAME, messages=messages)\n",
    "\n",
    "        logging.info(\"Response from Ollama: %s\", response)\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(\"Failed to run analysis: %s\", e)\n",
    "        return f\"Error in analysis: {e}\"\n",
    "\n",
    "# Run the async event loop with compatibility for interactive environments\n",
    "def main():\n",
    "    if asyncio.get_event_loop().is_running():\n",
    "        # If there's already an event loop running (e.g., in Jupyter), use it\n",
    "        return asyncio.create_task(run_ollama_analysis(IMAGE_PATH))\n",
    "    else:\n",
    "        # Otherwise, run a new event loop\n",
    "        asyncio.run(run_ollama_analysis(IMAGE_PATH))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"Launching Gemini Health App...\")\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
